{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14c37cf-fa12-45b0-8524-16d25221f263",
   "metadata": {},
   "source": [
    "# 1. Importing dependencies, setting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac9861-f8e2-4853-b05d-a0e3041e4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934340b-e2f0-4e3f-9a2f-219e9f0d56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import multiprocessing as mp\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9b3b4-2b43-4d22-8fe7-e2f39708a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 997\n",
    "# seed added for results reproducibility\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0d58-5331-4530-90ef-fc6057e1ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43839d8-0e67-4898-9f72-1b81b83b3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b450d-9bcd-4aa8-bfe6-ca7ed397804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # restriction for TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97784e-d517-498c-b436-3a825f925c14",
   "metadata": {},
   "source": [
    "# 2. Image generation by augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5c0f5-4793-48c1-982b-ba5cb765c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "IMG_X, IMG_Y = 320, 213 # proportion: 3:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216b9e2-8f30-462d-bb9e-9677e67fbc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_for_country(\n",
    "        country, directories, datagen, num_augmented_images=5\n",
    "    ) -> None:\n",
    "    country_input_path = os.path.join(directories['source_dir'], country)\n",
    "    country_output_path = os.path.join(directories['augmented_dir'], country)\n",
    "    os.makedirs(country_output_path, exist_ok=True)\n",
    "\n",
    "    for image_name in os.listdir(country_input_path):\n",
    "        img_path = os.path.join(country_input_path, image_name)\n",
    "        img = load_img(img_path)\n",
    "        img = img.resize((IMG_X, IMG_Y))\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "        # to size: (1, width, height, channels)\n",
    "        \n",
    "        i = 0\n",
    "        for batch in datagen.flow(\n",
    "            x, batch_size=1, save_to_dir=country_output_path, save_prefix='aug', save_format='jpeg'\n",
    "        ):\n",
    "            i += 1\n",
    "            if i >= num_augmented_images:\n",
    "                break\n",
    "\n",
    "def augment_images(directories, data_generator, num_augmented_images=5) -> None:\n",
    "    countries = os.listdir(directories['source_dir'])\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    pool.starmap(\n",
    "        augment_image_for_country,\n",
    "        [(country, directories, data_generator, num_augmented_images) for country in countries]\n",
    "    )\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748154f-467d-4ad3-ad6f-43268400851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj for augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90.0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=[0.8, 1.2],\n",
    "    channel_shift_range=51.0, # coding 0-255\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfe5da-b282-490c-9e1f-bfd1877828ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dict = {\n",
    "    'source_dir': 'data/country_flag',\n",
    "    'augmented_dir': 'data/augmented_flags',\n",
    "    'tfrecords': 'data/tfrecords',\n",
    "    'train_tfrecord': 'data/tfrecords/train.tfrecord',\n",
    "    'val_tfrecord': 'data/tfrecords/val.tfrecord',\n",
    "    'test_tfrecord': 'data/tfrecords/test.tfrecord',\n",
    "    'model': 'models/flag_classifier_model.h5',\n",
    "    'checkpoints': 'models/checkpoints/ckpt.weights.keras'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db326bfd-08c7-435b-8231-07840d0e8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_dict['augmented_dir']):\n",
    "    os.makedirs(dir_dict['augmented_dir'])\n",
    "    augment_images(dir_dict, datagen, num_augmented_images=200)\n",
    "    print(\"Augmentation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42dc8e-10dc-4d14-be81-40c65c136acc",
   "metadata": {},
   "source": [
    "# 3. Creation of TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8d422-49db-4705-8369-f5eb7a4e05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_example(image_string, label):\n",
    "    feature = {\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def write_tfrecord(images, labels, output_path):\n",
    "    \"\"\"Function to write images to TFRecord.\"\"\"\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        for img_path, label in zip(images, labels):\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((IMG_X, IMG_Y))\n",
    "            img = img.convert('RGB')\n",
    "            img_byte_arr = img.tobytes()\n",
    "\n",
    "            tf_example = image_example(img_byte_arr, label)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "def convert_to_tfrecord(directories, test_size=0.2, val_size=0.2):\n",
    "    countries = os.listdir(directories['augmented_dir'])\n",
    "    label_map = {country: idx for idx, country in enumerate(countries)}\n",
    "\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    for country, label in label_map.items():\n",
    "        country_input_path = os.path.join(directories['augmented_dir'], country)\n",
    "        for image_name in os.listdir(country_input_path):\n",
    "            img_path = os.path.join(country_input_path, image_name)\n",
    "            all_images.append(img_path)\n",
    "            all_labels.append(label)\n",
    "        \n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        all_images, all_labels, test_size=test_size, stratify=all_labels\n",
    "    )\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        train_images, train_labels, test_size=val_size, stratify=train_labels\n",
    "    )\n",
    "\n",
    "    write_tfrecord(train_images, train_labels, directories['train_tfrecord'])\n",
    "    write_tfrecord(val_images, val_labels, directories['val_tfrecord'])\n",
    "    write_tfrecord(test_images, test_labels, directories['test_tfrecord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa6d46-5e9e-4685-b845-05bb1bda7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_dict['tfrecords']):\n",
    "    os.makedirs(dir_dict['tfrecords'])\n",
    "    convert_to_tfrecord(dir_dict, test_size=0.1, val_size=0.1)\n",
    "    print(\"TFRecord conversion completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2894f-0d8e-45c8-939f-562b2453a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(dir_dict['tfrecords']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec1085-2e54-4141-bf3b-b66a9cac2856",
   "metadata": {},
   "source": [
    "# 4. Reading TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae547db-a784-4990-a61b-225bc46d9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = len(os.listdir(dir_dict['source_dir']))\n",
    "f'Number of flag classes: {NUM_CLASSES}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52973dfc-5cbf-429c-a630-f7ce2dc00d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(proto):\n",
    "    \"\"\" Function is used to parse the example. Returns respectively image and its label. \"\"\"\n",
    "    keys_to_features = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    image = tf.io.decode_raw(parsed_features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, [IMG_Y, IMG_X, 3])\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # normalization of image\n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_path, batch_size=32):\n",
    "    \"\"\" Creates a dataset from the TFRecord files. \"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060af3d-7cd6-4297-9f5e-53c9d70c6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_tfrecord_dataset(dir_dict['train_tfrecord'])\n",
    "val_dataset = load_tfrecord_dataset(dir_dict['val_tfrecord'])\n",
    "test_dataset = load_tfrecord_dataset(dir_dict['test_tfrecord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5620d3e-fa81-4c67-955b-61e709c056a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape, '\\n', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152edd1d-bf89-4c5c-92b6-4c75ca6384b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i] * 255).astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f682f51-6046-45e1-be50-9298d27f2216",
   "metadata": {},
   "source": [
    "# 5. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dd866-7ff3-41f1-b2a1-daf03a7b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "NUM_EPOCHS = 15\n",
    "PATIENCE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097761d-fbd6-493f-9f38-4da3de21f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(\n",
    "    weights='imagenet', include_top=False, input_shape=(IMG_Y, IMG_X, 3)\n",
    ")\n",
    "io_x = base_model.output\n",
    "io_x = GlobalAveragePooling2D()(io_x)\n",
    "io_x = Dense(1024, activation='selu', kernel_regularizer=l2(5e-5))(io_x)\n",
    "io_x = Dropout(0.2)(io_x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(io_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e668378-1ff9-41f4-9955-ba412abcb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd405d-a9c1-4d77-acfe-feaedae64ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = AdamW(learning_rate=2e-5)\n",
    "LOSS = 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0d1d7-4bcd-4c81-a156-651da2d7dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1f5de-8295-45ea-91b8-21cd1eddf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=OPTIMIZER, \n",
    "    loss=LOSS, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c94c77-775b-41ec-96f3-ebfcbd465243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    dir_dict['checkpoints'], monitor='val_accuracy',\n",
    "    mode='max',save_best_only=True\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=PATIENCE, restore_best_weights=True\n",
    ")\n",
    "callbacks = [checkpoint_cb, early_stopping_cb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406feae-b0b6-40fc-8827-a75aca06ffcd",
   "metadata": {},
   "source": [
    "# 6. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82ef5e-966e-4795-a5b1-3a46eac4af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS, \n",
    "    verbose=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d89965-f36e-4364-a979-08f3c4e3e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fec4b-33d0-405d-8941-d6dfa715e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(dir_dict['checkpoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6061691-dce1-4e03-8d7b-c03d4ad4b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_weights(dir_dict['checkpoints'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cead09b-ba58-4554-9d3e-697fae1d8a6e",
   "metadata": {},
   "source": [
    "# 7. Fine - tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c9784-f4c2-4102-a250-94b4306f43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreezing some layers for training continue\n",
    "# https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b\n",
    "UNFREEZE_FROM = 143\n",
    "FT_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105f1cf-adad-4135-a1ee-1bf4c6563576",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:UNFREEZE_FROM]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[UNFREEZE_FROM:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER, \n",
    "    loss=LOSS, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aab3f9-aaad-4b56-aa3b-54ed00473499",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, validation_data=val_dataset, epochs=FT_EPOCHS, \n",
    "    verbose=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c877d9-db55-4341-ac26-2b286aae9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00094bae-bfd9-402b-bb5f-2dcecda98934",
   "metadata": {},
   "source": [
    "# 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae158019-443c-4e5c-93bb-f3766da68843",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f99ec-b2f0-4319-95a7-1021d4621d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)\n",
    "print('Test precision:', test_precision)\n",
    "print('Test recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea9130-a21e-47d4-97dd-ab2705e6fc77",
   "metadata": {},
   "source": [
    "# 9. Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e379e-cd79-4493-a54e-ee62bd0bec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(dir_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52447d-87fa-4a5b-b2b0-1163dfb7b761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160dcfd4-2222-4e20-975b-ca80f3d644f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8683ec7-4a2f-4132-b3ad-16ef230f515a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
